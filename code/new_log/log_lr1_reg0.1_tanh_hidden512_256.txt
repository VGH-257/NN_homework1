[INFO] Training with hyperparameters: {'lr': 1.0, 'reg': 0.1, 'epochs': 30, 'batch_size': 128, 'hidden': [512, 256], 'activation': 'tanh', 'decay_every': 10, 'decay_rate': 0.5, 'output_path': '../ckpt/best_model_lr1_reg0.1_tanh_hidden512_256.npz', 'log_path': 'new_log/log_lr1_reg0.1_tanh_hidden512_256.txt'}
Epoch 1: val_acc = 0.0938, val_loss = 2.3026
Epoch 2: val_acc = 0.0938, val_loss = 2.3026
Epoch 3: val_acc = 0.0938, val_loss = 2.3026
Epoch 4: val_acc = 0.0938, val_loss = 2.3026
Epoch 5: val_acc = 0.0938, val_loss = 2.3026
Epoch 6: val_acc = 0.0938, val_loss = 2.3026
Epoch 7: val_acc = 0.0938, val_loss = 2.3026
Epoch 8: val_acc = 0.0938, val_loss = 2.3026
Epoch 9: val_acc = 0.0938, val_loss = 2.3026
Epoch 10: val_acc = 0.0938, val_loss = 2.3026
Epoch 11: val_acc = 0.0938, val_loss = 2.3026
Epoch 12: val_acc = 0.0938, val_loss = 2.3026
Epoch 13: val_acc = 0.0938, val_loss = 2.3026
Epoch 14: val_acc = 0.0938, val_loss = 2.3026
Epoch 15: val_acc = 0.0938, val_loss = 2.3026
Epoch 16: val_acc = 0.0938, val_loss = 2.3026
Epoch 17: val_acc = 0.0938, val_loss = 2.3026
Epoch 18: val_acc = 0.0938, val_loss = 2.3026
Epoch 19: val_acc = 0.0938, val_loss = 2.3026
Epoch 20: val_acc = 0.0938, val_loss = 2.3026
Epoch 21: val_acc = 0.0938, val_loss = 2.3026
Epoch 22: val_acc = 0.0938, val_loss = 2.3026
Epoch 23: val_acc = 0.0938, val_loss = 2.3027
Epoch 24: val_acc = 0.0938, val_loss = 2.3026
Epoch 25: val_acc = 0.0938, val_loss = 2.3027
Epoch 26: val_acc = 0.0938, val_loss = 2.3027
Epoch 27: val_acc = 0.0938, val_loss = 2.3027
Epoch 28: val_acc = 0.0938, val_loss = 2.3026
Epoch 29: val_acc = 0.0938, val_loss = 2.3026
Epoch 30: val_acc = 0.0938, val_loss = 2.3027
Test Accuracy: 0.1000
