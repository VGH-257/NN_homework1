[INFO] Training with hyperparameters: {'lr': 0.001, 'reg': 0.0, 'epochs': 30, 'batch_size': 128, 'hidden': [256, 128], 'activation': 'sigmoid', 'decay_every': 10, 'decay_rate': 0.5, 'output_path': '../ckpt/best_model_lr0.001_reg0_sigmoid_hidden256_128.npz', 'log_path': 'new_log/log_lr0.001_reg0_sigmoid_hidden256_128.txt'}
Epoch 1: val_acc = 0.1080, val_loss = 2.5250
Epoch 2: val_acc = 0.1080, val_loss = 2.5167
Epoch 3: val_acc = 0.1080, val_loss = 2.5089
Epoch 4: val_acc = 0.1080, val_loss = 2.5014
Epoch 5: val_acc = 0.1080, val_loss = 2.4943
Epoch 6: val_acc = 0.1080, val_loss = 2.4875
Epoch 7: val_acc = 0.1080, val_loss = 2.4810
Epoch 8: val_acc = 0.1080, val_loss = 2.4748
Epoch 9: val_acc = 0.1080, val_loss = 2.4689
Epoch 10: val_acc = 0.1080, val_loss = 2.4633
Epoch 11: val_acc = 0.1080, val_loss = 2.4605
Epoch 12: val_acc = 0.1080, val_loss = 2.4579
Epoch 13: val_acc = 0.1080, val_loss = 2.4553
Epoch 14: val_acc = 0.1080, val_loss = 2.4527
Epoch 15: val_acc = 0.1080, val_loss = 2.4502
Epoch 16: val_acc = 0.1080, val_loss = 2.4478
Epoch 17: val_acc = 0.1080, val_loss = 2.4454
Epoch 18: val_acc = 0.1080, val_loss = 2.4430
Epoch 19: val_acc = 0.1080, val_loss = 2.4407
Epoch 20: val_acc = 0.1080, val_loss = 2.4385
Epoch 21: val_acc = 0.1080, val_loss = 2.4374
Epoch 22: val_acc = 0.1080, val_loss = 2.4363
Epoch 23: val_acc = 0.1080, val_loss = 2.4352
Epoch 24: val_acc = 0.1080, val_loss = 2.4341
Epoch 25: val_acc = 0.1080, val_loss = 2.4331
Epoch 26: val_acc = 0.1080, val_loss = 2.4320
Epoch 27: val_acc = 0.1080, val_loss = 2.4310
Epoch 28: val_acc = 0.1080, val_loss = 2.4300
Epoch 29: val_acc = 0.1080, val_loss = 2.4289
Epoch 30: val_acc = 0.1080, val_loss = 2.4279
Test Accuracy: 0.0984
